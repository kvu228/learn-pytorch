{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a193b99e",
   "metadata": {},
   "source": "# Initial setup"
  },
  {
   "cell_type": "markdown",
   "id": "7fff0bbaa0e483c0",
   "metadata": {},
   "source": [
    "Checking the GPU infomation"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:12.228974Z",
     "start_time": "2024-11-14T16:19:12.120723Z"
    }
   },
   "source": "!nvidia-smi",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 14 23:19:12 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.03                 Driver Version: 566.03         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650      WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   61C    P8              4W /   54W |       1MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "82869afcd01a3906",
   "metadata": {},
   "source": [
    "Check CUDA version"
   ]
  },
  {
   "cell_type": "code",
   "id": "2a30791116e590f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:12.263896Z",
     "start_time": "2024-11-14T16:19:12.229981Z"
    }
   },
   "source": [
    "!nvcc --version"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Mon_Oct_24_19:40:05_Pacific_Daylight_Time_2022\n",
      "Cuda compilation tools, release 12.0, V12.0.76\n",
      "Build cuda_12.0.r12.0/compiler.31968024_0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "f0679b29747d44f5",
   "metadata": {},
   "source": [
    "Install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "id": "69d0383cec598710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:16.444755Z",
     "start_time": "2024-11-14T16:19:12.264902Z"
    }
   },
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124, https://pypi.ngc.nvidia.comNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torch in c:\\users\\kietvu\\testplace\\learn-pytorch\\venv\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in c:\\users\\kietvu\\testplace\\learn-pytorch\\venv\\lib\\site-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\kietvu\\testplace\\learn-pytorch\\venv\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\kietvu\\testplace\\learn-pytorch\\venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kietvu\\testplace\\learn-pytorch\\venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\kietvu\\testplace\\learn-pytorch\\venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kietvu\\testplace\\learn-pytorch\\venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kietvu\\testplace\\learn-pytorch\\venv\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\kietvu\\testplace\\learn-pytorch\\venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kietvu\\testplace\\learn-pytorch\\venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kietvu\\testplace\\learn-pytorch\\venv\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\kietvu\\testplace\\learn-pytorch\\venv\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kietvu\\testplace\\learn-pytorch\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "bd085430",
   "metadata": {},
   "source": [
    "Check torch version"
   ]
  },
  {
   "cell_type": "code",
   "id": "5f9e63cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.882511Z",
     "start_time": "2024-11-14T16:19:16.445762Z"
    }
   },
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "a6b8078a",
   "metadata": {},
   "source": "# Introducion to Tensors"
  },
  {
   "cell_type": "markdown",
   "id": "c5fba818-7732-45c2-b649-34509c9addf8",
   "metadata": {},
   "source": [
    "## What is tensor\n",
    "Tensor is a way to represent data in a **numerical** way.\n",
    "\n",
    "For example, you could represent an image as a tensor with shape [3, 224, 224] which would mean [colour_channels, height, width], as in the image has 3 colour channels (red, green, blue), a height of 224 pixels and a width of 224 pixels."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Scalar\n",
    "**Scalar** is a *single number*, it is *zero* dimension"
   ],
   "id": "f895f9957776e455"
  },
  {
   "cell_type": "code",
   "id": "243e93d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.903848Z",
     "start_time": "2024-11-14T16:19:19.883518Z"
    }
   },
   "source": [
    "# Creating tensor\n",
    "scalar  = torch.tensor(7)\n",
    "scalar"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "01c6f4de-acd4-4a4a-a6ab-226a80472d48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.908559Z",
     "start_time": "2024-11-14T16:19:19.904854Z"
    }
   },
   "source": [
    "# Dimension of scalar\n",
    "scalar.ndim"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.914702Z",
     "start_time": "2024-11-14T16:19:19.909565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# converse tensor back to int\n",
    "scalar.item()"
   ],
   "id": "7fd3c462de585cdf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Vector\n",
    "**Vector** is a *single* dimension  but can contain many numbers. It is similar to an array of numbers"
   ],
   "id": "fd49075a6965f88e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.922207Z",
     "start_time": "2024-11-14T16:19:19.915709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# vector\n",
    "vector = torch.tensor([1,2,3])\n",
    "vector"
   ],
   "id": "24f8edd4e48595f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can tell the number of dimension of tensor by counting `[` ",
   "id": "8ddb34dec31c735d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.927103Z",
     "start_time": "2024-11-14T16:19:19.923214Z"
    }
   },
   "cell_type": "code",
   "source": "vector.ndim",
   "id": "67911d46d125d4af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`shape` attribute tells how the elements inside tensor are arrange. The shape of the above vector will return `tourch.Size([3])`, which means there are **3** elements inside the tensor `([1,2,3])`",
   "id": "2e41836f79d4df14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.933171Z",
     "start_time": "2024-11-14T16:19:19.929110Z"
    }
   },
   "cell_type": "code",
   "source": "vector.shape",
   "id": "3ff5f5b243c08619",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Matrix\n",
    "Matrices are as flexible as vectors, except they've got an extra dimension. Matrix is similar to 2-D array"
   ],
   "id": "ad00314b67033912"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.941356Z",
     "start_time": "2024-11-14T16:19:19.934179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.tensor([[2,7,8],\n",
    "                      [9,10,11]])\n",
    "MATRIX"
   ],
   "id": "9cddeafd2c4c9eb8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.945908Z",
     "start_time": "2024-11-14T16:19:19.942363Z"
    }
   },
   "cell_type": "code",
   "source": "MATRIX.ndim",
   "id": "5192766e5ed3c408",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This `MATRIX` has shape `touch.Size([2,3])` because it is **2** elements deep and **3** elements wide",
   "id": "b6e501c4031323c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.955700Z",
     "start_time": "2024-11-14T16:19:19.946914Z"
    }
   },
   "cell_type": "code",
   "source": "MATRIX.shape",
   "id": "807014d4a3b6bae0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.961760Z",
     "start_time": "2024-11-14T16:19:19.956712Z"
    }
   },
   "cell_type": "code",
   "source": "MATRIX[0]",
   "id": "89efa3679acda985",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 7, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.968252Z",
     "start_time": "2024-11-14T16:19:19.962767Z"
    }
   },
   "cell_type": "code",
   "source": "MATRIX[1]",
   "id": "f21d35061921e315",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10, 11])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tensor\n",
    "Tensors can represent almost anything, it is an **n-dimensional** array of numbers"
   ],
   "id": "341b10c9c93b5e3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.974932Z",
     "start_time": "2024-11-14T16:19:19.969259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]]])\n",
    "TENSOR"
   ],
   "id": "c918a8f7e975fb56",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.980730Z",
     "start_time": "2024-11-14T16:19:19.975943Z"
    }
   },
   "cell_type": "code",
   "source": "TENSOR.ndim",
   "id": "ed61cb3449fd99a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.987183Z",
     "start_time": "2024-11-14T16:19:19.981737Z"
    }
   },
   "cell_type": "code",
   "source": "TENSOR.shape",
   "id": "3f5f82adc045e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:19.993983Z",
     "start_time": "2024-11-14T16:19:19.988190Z"
    }
   },
   "cell_type": "code",
   "source": "TENSOR[0]",
   "id": "ba90a4671ea60a5c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.000060Z",
     "start_time": "2024-11-14T16:19:19.994997Z"
    }
   },
   "cell_type": "code",
   "source": "TENSOR[0][0]",
   "id": "66a6c87ce15d13f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.006615Z",
     "start_time": "2024-11-14T16:19:20.001068Z"
    }
   },
   "cell_type": "code",
   "source": "TENSOR[0][1][2]",
   "id": "e479f7724c30320f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.012374Z",
     "start_time": "2024-11-14T16:19:20.007622Z"
    }
   },
   "cell_type": "code",
   "source": "TENSOR[0][2][2]",
   "id": "c9b0f874ecb054e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> In practice, you'll often see scalars and vectors denoted as *lowercase* letters such as `y` or `a`. And matrices and tensors denoted as *uppercase* letters such as `X` or `W`.\n",
    "> \n",
    "> The names matrix and tensor used interchangeably"
   ],
   "id": "e04bb5fe995bcf60"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Random Tensors\n",
    "### Why random tensor?\n",
    "Machine learning models such as neural networks manipulate and seek patterns within tensors. A machine learning model often starts out with **large random** tensors of numbers and adjusts these random numbers as it works through data to better represent it.\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> repeat`\n",
    "\n",
    "Torch random tensor - https://pytorch.org/docs/stable/generated/torch.rand.html"
   ],
   "id": "e7fdadb6760bb65f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.044022Z",
     "start_time": "2024-11-14T16:19:20.013381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a random tensor of size (3,4)\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ],
   "id": "401e90ef5f1ad61d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5734, 0.6561, 0.5107, 0.2216],\n",
       "        [0.6140, 0.9088, 0.3600, 0.4586],\n",
       "        [0.6185, 0.4502, 0.8427, 0.2894]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.053684Z",
     "start_time": "2024-11-14T16:19:20.045031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a random tensor with similar to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(224,224,3)) # height, width, color_channel\n",
    "random_image_size_tensor"
   ],
   "id": "305ac24d57eaa949",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9374, 0.5217, 0.2533],\n",
       "         [0.4250, 0.5079, 0.7082],\n",
       "         [0.9690, 0.5692, 0.9926],\n",
       "         ...,\n",
       "         [0.5389, 0.4754, 0.6624],\n",
       "         [0.4446, 0.0903, 0.5690],\n",
       "         [0.2147, 0.1302, 0.2986]],\n",
       "\n",
       "        [[0.8460, 0.9570, 0.3627],\n",
       "         [0.5787, 0.6512, 0.2536],\n",
       "         [0.3585, 0.2148, 0.1799],\n",
       "         ...,\n",
       "         [0.1377, 0.0815, 0.1731],\n",
       "         [0.1359, 0.1595, 0.7713],\n",
       "         [0.1767, 0.9399, 0.8927]],\n",
       "\n",
       "        [[0.9696, 0.3218, 0.8131],\n",
       "         [0.7769, 0.8822, 0.0609],\n",
       "         [0.6941, 0.9721, 0.8297],\n",
       "         ...,\n",
       "         [0.8777, 0.6674, 0.9017],\n",
       "         [0.7384, 0.0100, 0.2111],\n",
       "         [0.7782, 0.1699, 0.8112]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9396, 0.0864, 0.7873],\n",
       "         [0.3800, 0.1991, 0.9762],\n",
       "         [0.9529, 0.2393, 0.7735],\n",
       "         ...,\n",
       "         [0.4612, 0.1188, 0.4150],\n",
       "         [0.1453, 0.1011, 0.8764],\n",
       "         [0.4421, 0.3343, 0.3698]],\n",
       "\n",
       "        [[0.4423, 0.4601, 0.3442],\n",
       "         [0.8408, 0.3406, 0.5831],\n",
       "         [0.7203, 0.4308, 0.6588],\n",
       "         ...,\n",
       "         [0.2675, 0.6533, 0.8807],\n",
       "         [0.7082, 0.9584, 0.1210],\n",
       "         [0.9670, 0.9894, 0.4057]],\n",
       "\n",
       "        [[0.5082, 0.4274, 0.1840],\n",
       "         [0.1377, 0.0964, 0.8213],\n",
       "         [0.5401, 0.8912, 0.9150],\n",
       "         ...,\n",
       "         [0.4390, 0.9635, 0.9107],\n",
       "         [0.6252, 0.3964, 0.3429],\n",
       "         [0.2695, 0.9349, 0.6473]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.058889Z",
     "start_time": "2024-11-14T16:19:20.054698Z"
    }
   },
   "cell_type": "code",
   "source": "random_image_size_tensor.ndim, random_image_size_tensor.shape",
   "id": "de8515a3ad800d52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([224, 224, 3]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Zeros and ones",
   "id": "c4301043149af3d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.066774Z",
     "start_time": "2024-11-14T16:19:20.059899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ],
   "id": "a1d50bd7711a684e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.074323Z",
     "start_time": "2024-11-14T16:19:20.067784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ],
   "id": "14b91bae6c2a489d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Range of tensors and tensors-like\n",
    "\n",
    "Use `torch.arange(start, end, step)` to do so."
   ],
   "id": "74df42a8ca622ecd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.084688Z",
     "start_time": "2024-11-14T16:19:20.077335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use torch.range\n",
    "one_to_nice = torch.arange(start=0, end=10,step=1)\n",
    "one_to_nice"
   ],
   "id": "4591d5df015a773a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sometimes you might want one tensor of a certain type with the same shape as another tensor.",
   "id": "2529c9f217d96b34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.089570Z",
     "start_time": "2024-11-14T16:19:20.085695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ten_zeros = torch.zeros_like(one_to_nice)\n",
    "ten_zeros"
   ],
   "id": "1d61065fa5c707da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Get information from Tensor",
   "id": "53ee0d7d82833878"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Three of the most common attributes you'll want to find out about tensors are:\n",
    "\n",
    "- **shape** - what shape is the tensor? (some operations require specific shape rules)\n",
    "- **dtype** - what datatype are the elements within the tensor stored in?\n",
    "- **device** - what device is the tensor stored on? (usually GPU or CPU)"
   ],
   "id": "9c9ead5d406dfcd5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.096296Z",
     "start_time": "2024-11-14T16:19:20.090577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a random tensor\n",
    "some_tensor = torch.rand(3,4)\n",
    "print(some_tensor)\n",
    "print(f'shape: {some_tensor.shape}')\n",
    "print(f'type: {some_tensor.dtype}')\n",
    "print(f'device: {some_tensor.device}')\n"
   ],
   "id": "3510bc3673c51103",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2502, 0.9336, 0.4282, 0.2233],\n",
      "        [0.5097, 0.7481, 0.4589, 0.0513],\n",
      "        [0.9926, 0.6594, 0.3587, 0.1621]])\n",
      "shape: torch.Size([3, 4])\n",
      "type: torch.float32\n",
      "device: cpu\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tensor operations\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Substraction\n",
    "* Multiplication\n",
    "* Division\n",
    "* Matrix multiplication"
   ],
   "id": "2d7adfa5273c49ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Basic operations",
   "id": "1305c0ace9623775"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.103786Z",
     "start_time": "2024-11-14T16:19:20.097304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a tensor and add 10 to it\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ],
   "id": "c75acda645d1b293",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.110569Z",
     "start_time": "2024-11-14T16:19:20.104797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a tensor and subtract 10 to it\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor - 10"
   ],
   "id": "e9321daf8e469339",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.116491Z",
     "start_time": "2024-11-14T16:19:20.111579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a tensor and multiply 10 to it\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor * 10"
   ],
   "id": "c31faa5c6846e1f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.126860Z",
     "start_time": "2024-11-14T16:19:20.117498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a tensor and divide 2 to it\n",
    "tensor = torch.tensor([10,20,30])\n",
    "tensor / 2"
   ],
   "id": "8adca0069585faf5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5., 10., 15.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Matrix multiplication\n",
    "Two main ways of performing matrix multiplication in neural networks and deep learning:\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)\n",
    "\n",
    "More information - https://www.mathsisfun.com/algebra/matrix-multiplying.html"
   ],
   "id": "dd396fa7bb7c68c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.132945Z",
     "start_time": "2024-11-14T16:19:20.127870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Element wise multiplication\n",
    "tensor = torch.tensor([1,2,3])\n",
    "other_tensor = torch.tensor([4,5,6])\n",
    "print(f'{tensor} * {other_tensor} = {tensor * other_tensor}')"
   ],
   "id": "cf1cac23151d6516",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([4, 5, 6]) = tensor([ 4, 10, 18])\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.143243Z",
     "start_time": "2024-11-14T16:19:20.133952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# Matrix multiplication using torch\n",
    "torch.matmul(tensor, other_tensor)"
   ],
   "id": "32ef2e8fab104678",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.148065Z",
     "start_time": "2024-11-14T16:19:20.143243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# Matrix multiplication manually\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * other_tensor[i]\n",
    "print(value)"
   ],
   "id": "a91eabc24c5618dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1e+03 Î¼s\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Two rules when performing matrix multiplication:\n",
    "1. The **inner dimension** must match. \n",
    "    * `(3,2) @ (3,2)` won't work\n",
    "    *  `(2,3) @ (3,2)` will work\n",
    "    * `(3,2) @ (2,3)` will work\n",
    "2. The resulting matrix has the shape of the **outer dimensions**\n",
    "    * `(2,3) @ (3,2)` -> `(2,2)`\n",
    "    * `(3,2) @ (2,3)` -> `(3,3)` \n",
    "    * `(3,2) @ (2,6)` -> `(3,6)`"
   ],
   "id": "2d5eab4eb34c61f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:20.254153Z",
     "start_time": "2024-11-14T16:19:20.149072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_a = torch.tensor([[1,2],\n",
    "                   [3,4],\n",
    "                   [5,6]])\n",
    "\n",
    "tensor_b = torch.tensor([[7,8],\n",
    "                   [9,10],\n",
    "                   [11,23]])\n",
    "\n",
    "torch.matmul(tensor_a, tensor_b) # shape error"
   ],
   "id": "1a3ecd36513b4228",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 9\u001B[0m\n\u001B[0;32m      1\u001B[0m tensor_a \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([[\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m],\n\u001B[0;32m      2\u001B[0m                    [\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m4\u001B[39m],\n\u001B[0;32m      3\u001B[0m                    [\u001B[38;5;241m5\u001B[39m,\u001B[38;5;241m6\u001B[39m]])\n\u001B[0;32m      5\u001B[0m tensor_b \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([[\u001B[38;5;241m7\u001B[39m,\u001B[38;5;241m8\u001B[39m],\n\u001B[0;32m      6\u001B[0m                    [\u001B[38;5;241m9\u001B[39m,\u001B[38;5;241m10\u001B[39m],\n\u001B[0;32m      7\u001B[0m                    [\u001B[38;5;241m11\u001B[39m,\u001B[38;5;241m23\u001B[39m]])\n\u001B[1;32m----> 9\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor_a\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensor_b\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# shape error\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:43.151284Z",
     "start_time": "2024-11-14T16:19:43.145133Z"
    }
   },
   "cell_type": "code",
   "source": "torch.matmul(tensor_a,tensor_b.T) # (3,2) @ (2,3) -> work",
   "id": "38aeee246c616dc2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 23,  29,  57],\n",
       "        [ 53,  67, 125],\n",
       "        [ 83, 105, 193]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:44.482189Z",
     "start_time": "2024-11-14T16:19:44.472361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_a = torch.rand(2,3)\n",
    "tensor_b = torch.rand(3,2)\n",
    "tensor_c = torch.matmul(tensor_a, tensor_b)\n",
    "print(f'tensor_a @ tensor_b = {tensor_c}\\nShape: {tensor_c.shape}')          # size([2,2])"
   ],
   "id": "bdb5ea4db525aaa9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_a @ tensor_b = tensor([[0.8167, 0.7318],\n",
      "        [1.0870, 0.7900]])\n",
      "Shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:45.010124Z",
     "start_time": "2024-11-14T16:19:45.005487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_a = torch.rand(2,3)\n",
    "tensor_b = torch.rand(3,6)\n",
    "tensor_c = torch.matmul(tensor_a, tensor_b)\n",
    "print(f'tensor_a @ tensor_b = {tensor_c}\\nShape: {tensor_c.shape}')          # size([2,6])"
   ],
   "id": "1a6cdbd2758f888c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_a @ tensor_b = tensor([[0.7246, 0.2732, 0.5059, 0.8040, 0.6476, 0.5639],\n",
      "        [0.5769, 0.3542, 0.3080, 0.2568, 0.3356, 0.4479]])\n",
      "Shape: torch.Size([2, 6])\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tensor aggregations (min, max, sum, mean...)",
   "id": "8a4397b72df851e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:45.425308Z",
     "start_time": "2024-11-14T16:19:45.419532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.arange(start=0, end=100, step=10)\n",
    "x, x.type()"
   ],
   "id": "dcf98abd59cb1586",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), 'torch.LongTensor')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:45.730470Z",
     "start_time": "2024-11-14T16:19:45.691133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find min and max\n",
    "print(f'Min of x: {torch.min(x)} or {x.min()}')\n",
    "print(f'Max of x: {torch.max(x)} or {x.max()}')\n",
    "print(f'Mean of x: {torch.mean(x)}') # will get error of datatype"
   ],
   "id": "6bf21c0798d9d5b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min of x: 0 or 0\n",
      "Max of x: 90 or 90\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[43], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMin of x: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39mmin(x)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mmin()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMax of x: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39mmax(x)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mmax()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMean of x: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m# will get error of datatype\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:46.015417Z",
     "start_time": "2024-11-14T16:19:46.010300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cast x to dtype float32 before finding the mean\n",
    "# torch.mean() requires a tensor of floating point or complex dtype\n",
    "print(f'Mean of x: {torch.mean(x.type(torch.float32))} or {x.type(torch.float32).mean()}')\n",
    "\n",
    "# Note: x remains the init style\n",
    "print(f'dtype of x: {x.type()}')"
   ],
   "id": "10a4139a996472c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of x: 45.0 or 45.0\n",
      "dtype of x: torch.LongTensor\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:46.194257Z",
     "start_time": "2024-11-14T16:19:46.189634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find sum\n",
    "print(f'Sum of x: {torch.sum(x)} or {x.sum()}')"
   ],
   "id": "6296ee311c225870",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of x: 450 or 450\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:46.382026Z",
     "start_time": "2024-11-14T16:19:46.375467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find median\n",
    "print(f'Median of x: {torch.median(x)} or {x.median()}')"
   ],
   "id": "9a84545c33a0f8ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of x: 40 or 40\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Finding the positional of min and max",
   "id": "354739e687b32e80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:46.699191Z",
     "start_time": "2024-11-14T16:19:46.692596Z"
    }
   },
   "cell_type": "code",
   "source": "x, x.type()",
   "id": "7b98197cefe46aa8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), 'torch.LongTensor')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We use `argmin` or `argmax` to get the **position** of the min and max",
   "id": "9db080393eb38ff6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:47.169604Z",
     "start_time": "2024-11-14T16:19:47.164198Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'Min of x: {x.min()} at index: {x.argmin()}')",
   "id": "7d0ede817db93a4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min of x: 0 at index: 0\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:47.450643Z",
     "start_time": "2024-11-14T16:19:47.444048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_X = torch.rand(size=(3,4))\n",
    "tensor_X"
   ],
   "id": "debce3ee776d0a34",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7379, 0.4157, 0.4021, 0.5729],\n",
       "        [0.3263, 0.3853, 0.1679, 0.6958],\n",
       "        [0.5126, 0.7076, 0.0064, 0.7110]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:47.733395Z",
     "start_time": "2024-11-14T16:19:47.727024Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'Min of tensor_X: {tensor_X.min()} at {tensor_X.argmin()}')",
   "id": "9dcad7962b2f5dee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min of tensor_X: 0.006448566913604736 at 10\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Reshaping, stacking, squeezing and un-squeezing tensor\n",
    "* **Reshaping** - reshapes an input tensor to a defined shape\n",
    "* **View** - return a view of an input tensor of certain shape but **keep the same memory** as the original tensor\n",
    "* **Stacking** - combine multiple tensors on top of each other *(vstack)* or side by side *(hstack)*\n",
    "* **Squeeze** - remove all `1` dimensions from a tensor\n",
    "* **Unsqueeze** - add a `1` dimensions to a target tensor\n",
    "* **Permute** - return a view of the input with dimensions permuted (swapped) in a certain way"
   ],
   "id": "34bcad480b8105d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reshape and view\n",
    "When using `reshape` the number of elements in reshaped tensor and original tensor **must be equal**"
   ],
   "id": "6c690c76453a46ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:48.437127Z",
     "start_time": "2024-11-14T16:19:48.430953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.arange(1., 10.)\n",
    "x, x.shape, x.dtype"
   ],
   "id": "53bd6a0b870511d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]), torch.float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:48.678648Z",
     "start_time": "2024-11-14T16:19:48.659082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add an extra dimension\n",
    "x_reshaped = x.reshape(1,7)\n",
    "x_reshaped, x_reshaped.shape"
   ],
   "id": "a99ade9cd27561b1",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 7]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[52], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# add an extra dimension\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m x_reshaped \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m7\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m x_reshaped, x_reshaped\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[1;31mRuntimeError\u001B[0m: shape '[1, 7]' is invalid for input of size 9"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:48.852021Z",
     "start_time": "2024-11-14T16:19:48.846257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add an extra dimension\n",
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped, x_reshaped.shape"
   ],
   "id": "ebdebe6a97446de1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:49.197931Z",
     "start_time": "2024-11-14T16:19:49.191448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add an extra dimension\n",
    "x_reshaped = x.reshape(3, 3)\n",
    "x_reshaped, x_reshaped.shape"
   ],
   "id": "ca83ec2d30402846",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:49.429319Z",
     "start_time": "2024-11-14T16:19:49.424535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add an extra dimension\n",
    "x_reshaped = x.reshape(9,1)\n",
    "x_reshaped, x_reshaped.shape"
   ],
   "id": "a35e83044cfff972",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:49.766574Z",
     "start_time": "2024-11-14T16:19:49.751780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# add an extra dimension\n",
    "x_reshaped = x.reshape(10,1)\n",
    "x_reshaped, x_reshaped.shape"
   ],
   "id": "a2928878a3b689c2",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[10, 1]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[56], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# add an extra dimension\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m x_reshaped \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m x_reshaped, x_reshaped\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[1;31mRuntimeError\u001B[0m: shape '[10, 1]' is invalid for input of size 9"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Changing the view of a tensor with `torch.view()` only creates a new view of the same tensor. So changing the view **changes the original tensor** too.",
   "id": "48e39a02c63f3977"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:50.122412Z",
     "start_time": "2024-11-14T16:19:50.117085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "z = x.view(3,3)\n",
    "x, z "
   ],
   "id": "ce32428ca3a18c3e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:50.376499Z",
     "start_time": "2024-11-14T16:19:50.370079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "z[1,1] = 99 # change 5 -> 99 then x will be [1,2,3,4,99,6,7,8,9]\n",
    "x, z, x_reshaped"
   ],
   "id": "72d47d6a66d83d18",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4., 99.,  6.,  7.,  8.,  9.]),\n",
       " tensor([[ 1.,  2.,  3.],\n",
       "         [ 4., 99.,  6.],\n",
       "         [ 7.,  8.,  9.]]),\n",
       " tensor([[ 1.],\n",
       "         [ 2.],\n",
       "         [ 3.],\n",
       "         [ 4.],\n",
       "         [99.],\n",
       "         [ 6.],\n",
       "         [ 7.],\n",
       "         [ 8.],\n",
       "         [ 9.]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Stack",
   "id": "eff8aa71c8e1a9a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:50.950801Z",
     "start_time": "2024-11-14T16:19:50.944933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n",
    "x_stacked"
   ],
   "id": "475835b7c402d621",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4., 99.,  6.,  7.,  8.,  9.],\n",
       "        [ 1.,  2.,  3.,  4., 99.,  6.,  7.,  8.,  9.],\n",
       "        [ 1.,  2.,  3.,  4., 99.,  6.,  7.,  8.,  9.],\n",
       "        [ 1.,  2.,  3.,  4., 99.,  6.,  7.,  8.,  9.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:19:51.267575Z",
     "start_time": "2024-11-14T16:19:51.261379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Stack tensors side by side of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "x_stacked"
   ],
   "id": "dadced244fc7e7b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  1.,  1.],\n",
       "        [ 2.,  2.,  2.,  2.],\n",
       "        [ 3.,  3.,  3.,  3.],\n",
       "        [ 4.,  4.,  4.,  4.],\n",
       "        [99., 99., 99., 99.],\n",
       "        [ 6.,  6.,  6.,  6.],\n",
       "        [ 7.,  7.,  7.,  7.],\n",
       "        [ 8.,  8.,  8.,  8.],\n",
       "        [ 9.,  9.,  9.,  9.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Squeeze and unsqueeze\n",
    "Removing all single dimensions from a tensor, you can use `torch.squeeze()`"
   ],
   "id": "a743345253e8c481"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:26:18.937133Z",
     "start_time": "2024-11-14T16:26:18.932435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimension from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ],
   "id": "9d9bb357926244d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[ 1.],\n",
      "        [ 2.],\n",
      "        [ 3.],\n",
      "        [ 4.],\n",
      "        [99.],\n",
      "        [ 6.],\n",
      "        [ 7.],\n",
      "        [ 8.],\n",
      "        [ 9.]])\n",
      "Previous shape: torch.Size([9, 1])\n",
      "\n",
      "New tensor: tensor([ 1.,  2.,  3.,  4., 99.,  6.,  7.,  8.,  9.])\n",
      "New shape: torch.Size([9])\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And to do the reverse of `torch.squeeze()` you can use `torch.unsqueeze()` to add a dimension value of 1 at a specific index.",
   "id": "edca65efd67f0f36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:28:17.498369Z",
     "start_time": "2024-11-14T16:28:17.492992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ],
   "id": "98d759e91126f45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([ 1.,  2.,  3.,  4., 99.,  6.,  7.,  8.,  9.])\n",
      "Previous shape: torch.Size([9])\n",
      "\n",
      "New tensor: tensor([[ 1.,  2.,  3.,  4., 99.,  6.,  7.,  8.,  9.]])\n",
      "New shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Permute\n",
    "You can also rearrange the order of axes values with `torch.permute(input, dims)`, where the `input` gets turned into a view with new `dims`.\n",
    "For example: you might change the tensor of an image from (height,width,color-channels) -> (color-channels,height,width)  "
   ],
   "id": "43296fea1edd079"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:31:32.756868Z",
     "start_time": "2024-11-14T16:31:32.752114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create tensor with specific shape\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permute the original tensor to rearrange the axis order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ],
   "id": "98170ff1083f8c70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "execution_count": 69
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
